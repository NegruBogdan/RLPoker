{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd21e21",
   "metadata": {},
   "source": [
    "# Importuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b90ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "from treys import Deck\n",
    "from treys import Card\n",
    "from treys import Evaluator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1bc7c",
   "metadata": {},
   "source": [
    "#  Implementarea Agentului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnqAgent:\n",
    "    self.evaluator_agent = Evaluator()\n",
    "    self.gamma = 0.95\n",
    "    self.epsilon = 1.0\n",
    "    self.epsilon_decay = 0.99\n",
    "    self.epsilon_min = 0.001\n",
    "    self.epsilon_max = 1\n",
    "    self.learning_rate = 0.1\n",
    "    self.action_model = self._bulild_opponent_model()\n",
    "    self.last_opponent_action = None\n",
    "    self.hand_power \n",
    "    self.batch_size = 16\n",
    "    self.discount = 0.25\n",
    "    self.own_memory = deque(maxlen=1024)#memoria agentului\n",
    "    self.games_played = 0\n",
    "    self.last_action = None\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        self.games_played += 1\n",
    "        self.epsilon = max(self.epsilon_max - (self.games_played * (self.epsilon_max / self.epsilon_decay)),\n",
    "                           self.epsilon_min)\n",
    "    \n",
    "    def play(self,state):\n",
    "        if random.random() < self.epsilon:\n",
    "            action = random.choice(range(len(3))\n",
    "        else:\n",
    "            action = np.argmax(self.actiong_model.predict(np.asarray([state]))[0])\n",
    "        self.update_epsilon()\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def _bulild_model(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        \n",
    "        model.tf.keras.layers.InputLayer(input_shape=(10,))\n",
    "        model.tf.keras.layers.Add(Dense(4,activation = \"sigmoid\"))\n",
    "        model.tf.keras.layers.Add(Dense(3,activation = \"sigmoid\"))\n",
    "        \n",
    "        model.compile(loss = \"mse\",optimizer = Adam(lr.self.leaning_rate))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "                                   \n",
    "    def remember(state,action,reward,following_state, done):\n",
    "        self.own_memory.append(state,action,reward,following_state, done)\n",
    "                                   \n",
    "    def replay(self):\n",
    "        auxiliary_batch = random.sample(self.own_memory,self.batch_size)\n",
    "        for state,action,reward,following_state,done in auxiliary_batch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward+self.gamma * np.amax(self.action_model.predict(following_state)[0]))\n",
    "            target_f = self.action_model.predict(state)\n",
    "            target_f[o][action] = target\n",
    "            \n",
    "            self.action_model.fit(state,target_f,epochs =1,verbose = 0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsioln *=self.epsilon_decay\n",
    "    \n",
    "    \n",
    "                                   \n",
    "    def _peek(hand,table):\n",
    "        self.hand_power = 1-(evaluator_agent.evaluate(table, hand)-1)/7462\n",
    "    \n",
    "                                   \n",
    "    def make_state(previous_oponent_action,board,pot,stage):\n",
    "        if stage == \"flop\":\n",
    "            state = np.concatenate([1,0,0],[self.hand_power],[self.last_opponent_action],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        elif stage == \"turn\":\n",
    "            state = np.concatenate([0,1,0],[self.hand_power],[self.last_opponent_action],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        elif stage == \"river\":\n",
    "            state = np.concatenate([0,0,1],[self.hand_power],[self.last_opponent_action],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        else:\n",
    "             state = np.concatenate([0,0,0],[self.hand_power],[self.last_opponent_action],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        return state\n",
    "    \n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e87ee",
   "metadata": {},
   "source": [
    "### Cateva functii si clase ajutatoare in simularea environment-ului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e96f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassInfo:\n",
    "    def _init_(self):\n",
    "        self.round = None\n",
    "        self.precedentAction= None\n",
    "        self.potTotal = None\n",
    "        self.activePlayer = None\n",
    "        self.lastBet = None\n",
    "        \n",
    "    def NextPlayer(self):\n",
    "        self.activePlayer = (self.activePlayer +1 )%2\n",
    "    \n",
    "    def AddToPot(bet):\n",
    "        self.potTotal = self.potTotal + bet\n",
    "    \n",
    "    def CheckToRaise(self):\n",
    "        self.potTotal = self.potTotal + self.LastBet\n",
    "        \n",
    "    def Raise(self,bet):\n",
    "        self.AddToBet(bet)\n",
    "        self.lastBet = bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd82755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AceOnTable(table):\n",
    "    for ace in [Card.new('Ah'),Card.new('As'),Card.new('Ad'),Card.new('Ac')]:\n",
    "        if ace in table:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def KingOnTable(table):\n",
    "    for king in [Card.new('Kh'),Card.new('Ks'),Card.new('Kd'),Card.new('Kc')]:\n",
    "        if king in table:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableAction(ActionTaken,InfoToPass):\n",
    "    if ActionTaken == 0:\n",
    "        return InfoToPass.potTotal\n",
    "    elif ActionTaken == 1:\n",
    "        if InfoToPass.precedentAction == 1:\n",
    "            return None\n",
    "        else:\n",
    "            if InfoToPass.precedentAction == 2:\n",
    "                InfoToPass.CheckToRaise()\n",
    "                InfoToPass.NextPlayer()\n",
    "                BettingRound(InfoToPass, Agent)\n",
    "    elif ActionTaken == 2:\n",
    "        InfoToPass.NextPlayer()\n",
    "        BettingRound(InfoToPass, Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def BettingRound(InfoToPass, Agent):\n",
    "    if InfoToPass.activePlayer == 0:\n",
    "        ActionTaken = int(input(\"Selectati o actiune 0-fold,1-check,2-raise\"))\n",
    "        if ActionTaken == 0 or ActionTaken == 1:\n",
    "            #agentul memoreaza actiune\n",
    "            TableAction(ActionTaken,InfoToPass)\n",
    "        elif ActionTaken == 2:\n",
    "            #agentul memoreaza actiune\n",
    "            raised = int(input(\"Introduceti suma pariata peste potul curent:\"))\n",
    "            InfoToPass.Raise(raised)\n",
    "            TableAction(ActionTaken,InfoToPass)\n",
    "    else:\n",
    "        #decizieAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LiveGame(Agent):\n",
    "    InfoToPass = PassInfo()\n",
    "    InfoToPass.lastBet = 1\n",
    "    InfoToPass.precedentAction = 2\n",
    "    deck = Deck()\n",
    "    deck.shuffle()\n",
    "    my_hand=deck.draw(2)\n",
    "    agent_hand=deck.draw(2)\n",
    "    InfoTotPass.potTotal = blinds.sum()\n",
    "    if blinds[0] == 0:\n",
    "        InfoToPass.activePlayer = 0\n",
    "    else:\n",
    "        InfoToPass.activePlayer = 1\n",
    "    potAgent = 0\n",
    "    table = []\n",
    "    Agent._peek(agent_hand,table)\n",
    "    print(\"Mana dumneavoastra\")\n",
    "    print(list(Card.int_to_pretty_str(my_hand[i]) for i in range(2)))\n",
    "    #blind betting\n",
    "    result =  BettingRound(InfoToPass, Agent)\n",
    "    if result != None:\n",
    "        if InfoToPass.activePlayer == 1:\n",
    "            return -1 * result\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "    #the flop\n",
    "    InfoToPass.round = \"flop\"\n",
    "    deck.draw(1)\n",
    "    table.append(deck.draw(3))\n",
    "    Agent._peek(agent_hand,table)\n",
    "    print(\"Mana dumneavoastra\")\n",
    "    print(list(Card.int_to_pretty_str(my_hand[i]) for i in range(2)))\n",
    "    print(\"Cartile de pe masa\")\n",
    "    print(list(Card.int_to_pretty_str(table[i]) for i in range(3)))\n",
    "    result =  BettingRound(InfoToPass, Agent)\n",
    "    if result != None:\n",
    "        if InfoToPass.activePlayer == 1:\n",
    "            return -1 * result\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "    #the turn\n",
    "    InfoToPass.round=\"turn\"\n",
    "    deck.draw(1)\n",
    "    table.append(deck.draw(1))\n",
    "    Agent._peek(agent_hand,table)\n",
    "    print(\"Mana dumneavoastra\")\n",
    "    print(list(Card.int_to_pretty_str(my_hand[i]) for i in range(2)))\n",
    "    print(\"Cartile de pe masa\")\n",
    "    print(list(Card.int_to_pretty_str(table[i]) for i in range(4)))\n",
    "    result =  BettingRound(InfoToPass, Agent)\n",
    "    if result != None:\n",
    "        if InfoToPass.activePlayer == 1:\n",
    "            return -1 * result\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "    #the river\n",
    "    InfoToPass.round = \"river\"\n",
    "    deck.draw(1)\n",
    "    table.append(deck.draw(1))\n",
    "    Agent._peek(agent_hand,table)\n",
    "    print(\"Mana dumneavoastra\")\n",
    "    print(list(Card.int_to_pretty_str(my_hand[i]) for i in range(2)))\n",
    "    print(\"Cartile de pe masa\")\n",
    "    print(list(Card.int_to_pretty_str(table[i]) for i in range(5)))\n",
    "    result =  BettingRound(InfoToPass, Agent)\n",
    "    \n",
    "    if result != None:\n",
    "        if InfoToPass.activePlayer == 1:\n",
    "            return -1 * result\n",
    "        else:\n",
    "            return result\n",
    "    else:\n",
    "        evaluator = Evaluator()\n",
    "        if evaluator.evaluate(table, agent_hand) > evaluator.evaluate(table, my_hand):\n",
    "            return InfoToPass.potTotal \n",
    "        elif evaluator.evaluate(table, agent_hand) < evaluator.evaluate(table, my_hand):\n",
    "            return -1*InfoToPass.potTotal\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a85a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoAgentsBettingRound(InfoToPass, Agent,DummyAgent):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a243c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoAgentsTableAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimulateGame(Agent,DummyAgent):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d773674",
   "metadata": {},
   "source": [
    "#### Simulari a diferite abordari a jocului,cu scop de antrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafePlayerSimulator:\n",
    "    def __init__(self):\n",
    "        self.hand = None\n",
    "        self.evaluator = Evaluator()\n",
    "        \n",
    "    def look_at_hand(cards):\n",
    "        self.hand= cards\n",
    "    \n",
    "    def action(table):\n",
    "        if 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.75:\n",
    "            return 2\n",
    "        elif 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "class AgressivePlayerSimulator:\n",
    "    def __init__(self):\n",
    "        self.hand = None\n",
    "        self.evaluator = Evaluator()\n",
    "    \n",
    "    def look_at_hand(cards):\n",
    "        self.hand= cards\n",
    "    \n",
    "    def action(table):\n",
    "        if 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.5:\n",
    "            return 1\n",
    "        elif 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.25:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class PassivePlayerSimulator:\n",
    "    def __init__(self):\n",
    "        self.hand = None\n",
    "        self.evaluator = Evaluator()\n",
    "        \n",
    "    def look_at_hand(cards):\n",
    "        self.hand= cards\n",
    "    \n",
    "    def action(table):\n",
    "        if 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.9:\n",
    "            return 2\n",
    "        elif 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.7:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3c9cc",
   "metadata": {},
   "source": [
    "# Antrenarea Agentului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdebe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cddd3b7",
   "metadata": {},
   "source": [
    "# Experimentati agentul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ef030",
   "metadata": {},
   "outputs": [],
   "source": [
    "blinds = [0,1]\n",
    "Agent = DnqAgent()\n",
    "activ = True\n",
    "while activ:\n",
    "    Game(LiveAgent)\n",
    "    var = int(input(\"Runda s-a terminat.Continuati?(0 pentru a va opti,1 pentru a va opri)\"))\n",
    "    if var ==0:\n",
    "        activ = False\n",
    "    blinds.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23620bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
