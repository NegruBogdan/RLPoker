{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd21e21",
   "metadata": {},
   "source": [
    "# Importuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b90ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "from treys import Deck\n",
    "from treys import Card\n",
    "from treys import Evaluator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1bc7c",
   "metadata": {},
   "source": [
    "#  Implementarea Agentului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnqAgent:\n",
    "    self.evaluator_agent = Evaluator()\n",
    "    self.gamma = 0.95\n",
    "    self.epsilon = 1.0\n",
    "    self.epsilon_decay = 0.99\n",
    "    self.epsilon_min = 0.001\n",
    "    self.epsilon_max = 1\n",
    "    self.learning_rate = 0.4\n",
    "    self.action_model = self._bulild_opponent_model()\n",
    "    self.last_action = None\n",
    "    self.hand_power \n",
    "    self.batch_size = 16\n",
    "    self.discount = 0.25\n",
    "    self.own_memory = deque(maxlen=1024)#memoria agentului\n",
    "    self.games_played = 0\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        self.games_played += 1\n",
    "        self.epsilon = max(self.epsilon_max - (self.games_played * (self.epsilon_max / self.epsilon_decay)),\n",
    "                           self.epsilon_min)\n",
    "    \n",
    "    def play(self,state):\n",
    "        if random.random() < self.epsilon:\n",
    "            action = random.choice(range(len(3))\n",
    "        else:\n",
    "            action = np.argmax(self.actiong_model.predict(np.asarray([state]))[0])\n",
    "        self.update_epsilon()\n",
    "        epsilons.append(self.epsilon)\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def _bulild_model(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        \n",
    "        model.tf.keras.layers.InputLayer(input_shape=(9,))\n",
    "        model.tf.keras.layers.Add(Dense(4,activation = \"sigmoid\"))\n",
    "        model.tf.keras.layers.Add(Dense(3,activation = \"sigmoid\"))\n",
    "        \n",
    "        model.compile(loss = \"mse\",optimizer = Adam(lr.self.leaning_rate))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "                                   \n",
    "    def remember(state,action,reward,following_state, done):\n",
    "        self.own_memory.append(state,action,reward,following_state, done)\n",
    "                                   \n",
    "    def replay(self):\n",
    "        auxiliary_batch = random.sample(self.own_memory,self.batch_size)\n",
    "        for state,action,reward,following_state,done in auxiliary_batch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward+self.gamma * np.amax(self.action_model.predict(following_state)[0]))\n",
    "            target_f = self.action_model.predict(state)\n",
    "            target_f[o][action] = target\n",
    "            \n",
    "            self.action_model.fit(state,target_f,epochs =1,verbose = 0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *=self.epsilon_decay\n",
    "            epsilons.append(self.epsilon)\n",
    "    \n",
    "    \n",
    "                                   \n",
    "    def _peek(hand,table):\n",
    "        self.hand_power = 1-(evaluator_agent.evaluate(table, hand)-1)/7462\n",
    "    \n",
    "                                   \n",
    "    def make_state(previous_oponent_action,board,pot,stage):\n",
    "        if stage == \"flop\":\n",
    "            state = np.concatenate([1,0,0],[self.hand_power],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        elif stage == \"turn\":\n",
    "            state = np.concatenate([0,1,0],[self.hand_power],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        elif stage == \"river\":\n",
    "            state = np.concatenate([0,0,1],[self.hand_power],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        else:\n",
    "             state = np.concatenate([0,0,0],[self.hand_power],[previous_oponent_action],[self.last_action],[pot],[AceOnTable(table)],[KingOnTable(table)])\n",
    "        return state\n",
    "    \n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e87ee",
   "metadata": {},
   "source": [
    "### Cateva functii si clase ajutatoare in simularea environment-ului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e96f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassInfo:\n",
    "    def _init_(self):\n",
    "        self.round = None\n",
    "        self.precedentAction= None\n",
    "        self.potTotal = None\n",
    "        self.activePlayer = None\n",
    "        self.lastBet = None\n",
    "        \n",
    "    def NextPlayer(self):\n",
    "        self.activePlayer = (self.activePlayer +1 )%2\n",
    "    \n",
    "    def AddToPot(bet):\n",
    "        self.potTotal = self.potTotal + bet\n",
    "    \n",
    "    def CheckToRaise(self):\n",
    "        self.potTotal = self.potTotal + self.LastBet\n",
    "        \n",
    "    def Raise(self,bet):\n",
    "        self.AddToBet(self.lastBet)\n",
    "        self.AddToBet(bet)\n",
    "        self.lastBet = bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd82755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AceOnTable(table):\n",
    "    for ace in [Card.new('Ah'),Card.new('As'),Card.new('Ad'),Card.new('Ac')]:\n",
    "        if ace in table:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def KingOnTable(table):\n",
    "    for king in [Card.new('Kh'),Card.new('Ks'),Card.new('Kd'),Card.new('Kc')]:\n",
    "        if king in table:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableAction(ActionTaken,InfoToPass):\n",
    "    if ActionTaken == 0:\n",
    "        return True\n",
    "    elif ActionTaken == 1:\n",
    "        if InfoToPass.precedentAction == 1:\n",
    "            return False\n",
    "        else:\n",
    "            if InfoToPass.precedentAction == 2:\n",
    "                InfoToPass.CheckToRaise()\n",
    "                InfoToPass.NextPlayer()\n",
    "                return False\n",
    "    elif ActionTaken == 2:\n",
    "        InfoToPass.NextPlayer()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26588aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetRoundAgent(Agent,InfoToPass):\n",
    "    current_state = Agent.make_state(InfoToPass.precedentAction,board,InfoToPass.potTotal,InfoToPass.round)\n",
    "    action = Agent.play(current_state)\n",
    "    Agent.last_action =action\n",
    "    InfoToPass.precedentAction = action\n",
    "    if action = 2:\n",
    "        bet = radom.randint(1,10)\n",
    "    InfoToPass.Raise(bet)\n",
    "    return current_state,action\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ab786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetRoundOponent(DummyAgent,InfoToPass,table):\n",
    "    action = DummyAgent.action(table)\n",
    "    InfoToPass.precedentAction = action\n",
    "    if action = 2:\n",
    "        bet = radom.randint(1,10)\n",
    "    InfoToPass.Raise(bet)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a85a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimulateGame(Agent,DummyAgent):\n",
    "    InfoToPass = PassInfo()\n",
    "    InfoToPass.lastBet = 1\n",
    "    InfoToPass.precedentAction = 2\n",
    "    deck = Deck()\n",
    "    deck.shuffle()\n",
    "    trainer_hand=deck.draw(2)\n",
    "    agent_hand=deck.draw(2)\n",
    "    DummyAgent.look_at_hand(trainer_hand)\n",
    "    InfoTotPass.potTotal = blinds.sum()\n",
    "    if blinds[0] == 0:\n",
    "        InfoToPass.activePlayer = 0\n",
    "    else:\n",
    "        InfoToPass.activePlayer = 1\n",
    "    potAgent = 0\n",
    "    table = []\n",
    "    Agent._peek(agent_hand,table)\n",
    "    #blind betting\n",
    "    betting_round_going = True\n",
    "    if InfoToPass.activePlayer == 0:\n",
    "        while betting_round_going:\n",
    "            action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,action,reward,next_state, done)\n",
    "            state = next_state\n",
    "    else:\n",
    "        while betting_round_going:\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "            action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,Agent.nlast_action,reward,next_state, done)\n",
    "            state = next_state\n",
    "        \n",
    "    #the flop\n",
    "    InfoToPass.round = \"flop\"\n",
    "    deck.draw(1)\n",
    "    table.append(deck.draw(3))\n",
    "    Agent._peek(agent_hand,table)\n",
    "    \n",
    "    betting_round_going = True\n",
    "    if InfoToPass.activePlayer == 0:\n",
    "        while betting_round_going:\n",
    "            action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,action,reward,next_state, done)\n",
    "            state = next_state\n",
    "    else:\n",
    "        while betting_round_going:\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "            action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,Agent.nlast_action,reward,next_state, done)\n",
    "            state = next_state\n",
    "    #the turn\n",
    "    InfoToPass.round=\"turn\"\n",
    "    deck.draw(1)\n",
    "    table.append(deck.draw(1))\n",
    "    Agent._peek(agent_hand,table)\n",
    "    \n",
    "    betting_round_going = True\n",
    "    if InfoToPass.activePlayer == 0:\n",
    "        while betting_round_going:\n",
    "            action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,action,reward,next_state, done)\n",
    "            state = next_state\n",
    "    else:\n",
    "        while betting_round_going:\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "            if\n",
    "                action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,Agent.nlast_action,reward,next_state, done)\n",
    "            state = next_state\n",
    "        \n",
    "    #the river\n",
    "    InfoToPass.round = \"river\"\n",
    "    deck.draw(1)\n",
    "    table.append(deck.draw(1))\n",
    "    Agent._peek(agent_hand,table)\n",
    "    betting_round_going = True\n",
    "    if InfoToPass.activePlayer == 0:\n",
    "        while betting_round_going:\n",
    "            action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            if betting_round_going:\n",
    "                next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "                BetRoundAgent(Agent,InfoToPass)\n",
    "                betting_round_going=TableAction(action,InfoToPass)\n",
    "                if betting_round_going:\n",
    "                    done = False\n",
    "                else:\n",
    "                    if action = 0:\n",
    "                        done = True\n",
    "                        reward = -1*InfoToPass.potTotal\n",
    "                    else:\n",
    "                        done = True\n",
    "                        reward = 0\n",
    "                reward = reward if done else 0\n",
    "                rewards.append(reward)\n",
    "                Agent.remember(state,action,reward,next_state, done)\n",
    "                state = next_state\n",
    "    else:\n",
    "        while betting_round_going:\n",
    "            next_state,action = BetRoundAgent(Agent,InfoToPass)\n",
    "            BetRoundAgent(Agent,InfoToPass)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going:\n",
    "                done = False\n",
    "            else:\n",
    "                if action = 0:\n",
    "                    done = True\n",
    "                    reward = -1*InfoToPass.potTotal\n",
    "                else:\n",
    "                    done = True\n",
    "                    evaluator = Evaluator()\n",
    "                    if evaluator.evaluate(table,trainer_hand) < evaluator.evaluate(table,agent_hand):\n",
    "                        reward = InfoToPass.potTotal\n",
    "                    else:\n",
    "                        reward = -1*InfoToPass.potTotal\n",
    "            if betting_round_going:\n",
    "                action = BetRoundOponent(DummyAgent,InfoToPass,table)\n",
    "            betting_round_going=TableAction(action,InfoToPass)\n",
    "            if betting_round_going = False:\n",
    "                done = True\n",
    "                reward = InfoToPass.potTotal\n",
    "            reward = reward if done else 0\n",
    "            rewards.append(reward)\n",
    "            Agent.remember(state,Agent.nlast_action,reward,next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d773674",
   "metadata": {},
   "source": [
    "#### Simulari a diferite abordari a jocului,cu scop de antrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafePlayerSimulator:\n",
    "    def __init__(self):\n",
    "        self.hand = None\n",
    "        self.evaluator = Evaluator()\n",
    "        \n",
    "    def look_at_hand(cards):\n",
    "        self.hand= cards\n",
    "    \n",
    "    def action(table):\n",
    "        if 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.75:\n",
    "            return 2\n",
    "        elif 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "class AgressivePlayerSimulator:\n",
    "    def __init__(self):\n",
    "        self.hand = None\n",
    "        self.evaluator = Evaluator()\n",
    "    \n",
    "    def look_at_hand(cards):\n",
    "        self.hand= cards\n",
    "    \n",
    "    def action(table):\n",
    "        if 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.5:\n",
    "            return 1\n",
    "        elif 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.25:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class PassivePlayerSimulator:\n",
    "    def __init__(self):\n",
    "        self.hand = None\n",
    "        self.evaluator = Evaluator()\n",
    "        \n",
    "    def look_at_hand(cards):\n",
    "        self.hand= cards\n",
    "    \n",
    "    def action(table):\n",
    "        if 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.9:\n",
    "            return 2\n",
    "        elif 1-(evaluator_agent.evaluate(table, self.hand)-1)/7462 >  0.7:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3c9cc",
   "metadata": {},
   "source": [
    "# Antrenarea Agentului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdebe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "trainer1 = SafePlayerSimulator()\n",
    "trainer2 = AggressivePlayerSimulator()\n",
    "trainer3 = PassivePlayerSimulator()\n",
    "Agent = DnqAgent()\n",
    "for attempt in range(3000):\n",
    "    if attempt % 3 == 1:\n",
    "        SimulateGame(Agent,trainer1)\n",
    "    elif attempt%3==2:\n",
    "        SimulateGame(Agent,trainer2)\n",
    "    else:\n",
    "        SimulateGame(Agent,trainer3)\n",
    "        \n",
    "plt.title(\"Reward evolution\")\n",
    "plt.xlabel(\"total reward\")\n",
    "plt.ylabel(\"games played\")\n",
    "plt.plot(np.cumsum(rewards),[i for i in range(len(rewards))], color =\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddd3b7",
   "metadata": {},
   "source": [
    "# Experimentati agentul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ef030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
